{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af8c6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-26T06:59:54.510854500Z",
     "start_time": "2023-09-26T06:59:54.480145300Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import ConvNet, SoftBinaryDecisionTree\n",
    "from models.utils import brand_new_tfsession, draw_tree\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "sess = brand_new_tfsession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a5b59",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#上采样\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import *\n",
    "# from keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import xlwt\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "\n",
    "original_data = pd.read_csv('./dataset/SOFTLAB/ar3.csv')\n",
    "# original_data = pd.read_csv('./dataset/bugzilla.csv')\n",
    "original_data.isnull().values.any()  # Gives false ie:No null value in dataset\n",
    "original_data = original_data.fillna(value=False)  #将缺失值填充为False\n",
    "# original_Y = original_data['defects']  #Defective   class   isDefective  defects\n",
    "original_Y = original_data['defects']\n",
    "original_Y = pd.DataFrame(original_Y)\n",
    "original_data = normalization(original_data)\n",
    "\n",
    "#  将数据写入新文件  \n",
    "#original_data.to_excel('C:/Users/lenovo/Desktop/excel/ar6.xls',sheet_name='ar6',index=False)\n",
    "# original_X = pd.DataFrame(original_data.drop(['defects'], axis=1))  #Defective   class  isDefective  defects\n",
    "original_X = pd.DataFrame(original_data.drop(['defects'], axis=1))\n",
    "#print(original_X)\n",
    "#分为训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(original_X, original_Y, test_size=.1, random_state=12)\n",
    "# now we resample, and from that we take training and validation sets\n",
    "sm = SMOTE(random_state=12, sampling_strategy=1.0) # 解决分类不平衡问题\n",
    "x, y = sm.fit_resample(x_train, y_train)\n",
    "y_train = pd.DataFrame(y, columns=['defects']) #Defective  class  isDefective  defects\n",
    "x_train = pd.DataFrame(x, columns=original_X.columns)\n",
    "#print(x_test) \n",
    "\n",
    "#对单个数据进行加量 \n",
    "#x_test.loc[1,'total_loc'] =  0.264528801 \n",
    "#x_test.loc[1,'comment_loc'] =  0.337140831 \n",
    "#x_test.loc[1,'executable_loc'] =  0.203275228 \n",
    "#x_test.loc[1,'unique_operands'] =  0.369565217 \n",
    "#x_test.loc[1,'unique_operators'] =  0.479770399 \n",
    "#x_test.loc[1,'total_operands'] =  0.282879173 \n",
    "#x_test.loc[1,'total_operators'] =  0.250517298 \n",
    "#x_test.loc[1,'halstead_vocabulary'] =  0.414459875 \n",
    "#x_test.loc[1,'halstead_length'] =  0.262842023 \n",
    "#x_test.loc[1,'halstead_volume'] =  0.244372278 \n",
    "#x_test.loc[1,'halstead_level'] =  0.500382013 \n",
    "#x_test.loc[1,'halstead_difficulty'] =  0.280770116 \n",
    "#x_test.loc[1,'halstead_effort'] =  0.152186111 \n",
    "#x_test.loc[1,'halstead_time'] =  0.152185296 \n",
    "#x_test.loc[1,'branch_count'] =  0.172317183 \n",
    "#x_test.loc[1,'condition_count'] =  0.171775777 \n",
    "#x_test.loc[1,'cyclomatic_complexity'] =  0.179914274 \n",
    "#x_test.loc[1,'cyclomatic_density'] =  0.646325185 \n",
    "#x_test.loc[1,'decision_density'] =  0.290946038 \n",
    "#x_test.loc[1,'design_density'] =  0.200977818 \n",
    "#x_test.loc[1,'normalized_cyclomatic_complexity'] =  0.455357667 \n",
    "\n",
    "#细分出验证集\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.1, random_state=12)\n",
    "\n",
    "x_train = x_train.values\n",
    "x_val = x_val.values\n",
    "x_test = x_test.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "y_test = y_test.values\n",
    "\n",
    "img_rows, img_cols = 13,2 #7 3   13,2\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58f0aa",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_chans, n_classes = 13,2, 1, 2  #7,3   13,2\n",
    "print(img_rows, img_cols, img_chans, n_classes)\n",
    "\n",
    "# retrieve image and label shapes from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4d6e8",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# convert labels to 1-hot vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, n_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384884ba",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# normalize inputs and cast to float\n",
    "x_train = (x_train / np.max(x_train)).astype(np.float32)\n",
    "x_val = (x_val / np.max(x_val)).astype(np.float32)\n",
    "x_test = (x_test / np.max(x_test)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d9231",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "batch_size = 2\n",
    "# data_valid = (x_val, y_val)\n",
    "nn = ConvNet(img_rows, img_cols, img_chans, n_classes)\n",
    "nn.maybe_train(data_train=(x_train, y_train),\n",
    "               data_valid=(x_val, y_val),\n",
    "               batch_size=4, epochs=40)  #batch_size=4 2\n",
    "# nn.maybe_train(x_train, y_train, validation_data=data_valid,batch_size=batch_size, epochs=epochs)\n",
    "nn.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76afadd",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nn.evaluate(x_val, y_val)\n",
    "nn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1bcb6",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_train_soft = nn.predict(x_train)\n",
    "# print(y_train_soft)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25efdc66",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y = nn.predict(x_test)\n",
    "\n",
    "y = np.argmax(y,axis=1)\n",
    "y_test = np.argmax(y_test,axis=1)\n",
    "\n",
    "accuracy_score=metrics.accuracy_score(y_test,y)\n",
    "\n",
    "print(\"accuracy_score\",accuracy_score)\n",
    "\n",
    "precision=metrics.precision_score(y_test,y,average='macro')\n",
    "\n",
    "print(\"precision=\",precision)#precision对比可以，超过图中方法\n",
    "\n",
    "recall=metrics.recall_score(y_test,y,average='macro')\n",
    "print(\"recall=\",recall)#recall比其他两种方法都要低\n",
    "\n",
    "fscore=metrics.f1_score(y_test,y,average='macro')\n",
    "print(\"f-score=\",fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b8318",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
    "x_val_flat = x_val.reshape((x_val.shape[0], -1))\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "x_train_flat.shape, x_val_flat.shape, x_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1864e3ae",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n_features = img_rows * img_cols * img_chans\n",
    "tree_depth = 4\n",
    "penalty_strength = 1e+1 \n",
    "penalty_decay = 0.25\n",
    "ema_win_size = 1000\n",
    "inv_temp = 0.01\n",
    "learning_rate = 1e-06  \n",
    "batch_size = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6676c2",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sess = brand_new_tfsession(sess)\n",
    "\n",
    "tree1 = SoftBinaryDecisionTree(tree_depth, n_features, n_classes,\n",
    "    penalty_strength=penalty_strength, penalty_decay=penalty_decay,\n",
    "    inv_temp=inv_temp, ema_win_size=ema_win_size, learning_rate=learning_rate)\n",
    "tree1.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c602c5a7",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience=20, verbose=1)\n",
    "\n",
    "tree1.maybe_train(\n",
    "    sess=sess, data_train=(x_train_flat, y_train), data_valid=(x_val_flat, y_val),\n",
    "    batch_size=batch_size, epochs=epochs, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ba029",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tree1.evaluate(x=x_val_flat, y=y_val, batch_size=2)\n",
    "tree1.evaluate(x=x_test_flat, y=y_test, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e32c18",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sess = brand_new_tfsession(sess)\n",
    "\n",
    "tree1 = SoftBinaryDecisionTree(tree_depth, n_features, n_classes,\n",
    "    penalty_strength=penalty_strength, penalty_decay=penalty_decay,\n",
    "    inv_temp=inv_temp, ema_win_size=ema_win_size, learning_rate=learning_rate)\n",
    "tree1.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed46941",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience=20, verbose=1)\n",
    "\n",
    "tree1.maybe_train(\n",
    "    sess=sess, data_train=(x_train_flat, y_train_soft), data_valid=(x_val_flat, y_val),\n",
    "    batch_size=batch_size, epochs=epochs, callbacks=[es], distill=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d3293",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tree1.evaluate(x=x_val_flat, y=y_val, batch_size=1)\n",
    "\n",
    "tree1.evaluate(x=x_test_flat, y=y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f68514",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4806271655352e-07\n",
      "-3.599453538290518e-07\n",
      "-7.690680047896341e-07\n",
      "-3.374539856507957e-07\n",
      "3.0006822402911303e-07\n",
      "-3.56190292034977e-07\n",
      "3.653482248065968e-07\n",
      "3.2172538418763314e-07\n",
      "0.0\n",
      "0.0\n",
      "-2.9000535936196956e-07\n",
      "-3.7189962000576484e-07\n",
      "4.991842260342794e-07\n",
      "4.991844536173576e-07\n",
      "8.514480284743533e-07\n",
      "0.0\n",
      "0.0\n",
      "-3.3225452017003854e-07\n",
      "2.5214147702874236e-07\n",
      "-3.6501322738325167e-07\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#度量元灵敏度计算\n",
    "\n",
    "#增量为方差\n",
    "loss   = 12.62952525799091   #53.85\n",
    "loss1  = 12.629525331350473\n",
    "loss2  = 12.629525184631348\n",
    "loss3  = 12.629525111271786\n",
    "loss4  = 12.629525184631348\n",
    "loss5  = 12.629525331350473\n",
    "loss6  = 12.629525184631348\n",
    "loss7  = 12.629525331350473\n",
    "loss8  = 12.629525331350473\n",
    "loss9  = 12.62952525799091\n",
    "loss10 = 12.62952525799091\n",
    "loss11 = 12.629525184631348\n",
    "loss12 = 12.629525184631348\n",
    "loss13 = 12.629525331350473\n",
    "loss14 = 12.629525331350473\n",
    "loss15 = 12.629525404710035\n",
    "loss16 = 12.62952525799091\n",
    "loss17 = 12.62952525799091\n",
    "loss18 = 12.629525184631348\n",
    "loss19 = 12.629525331350473    #46.15% \n",
    "loss20 = 12.629525184631348\n",
    "loss21 = 12.62952525799091\n",
    "\n",
    "Sensitivity1 = (loss1 - loss) / 0.21076536\n",
    "Sensitivity2 = (loss2 - loss) / 0.203807498\n",
    "Sensitivity3 = (loss3 - loss) / 0.190775228\n",
    "Sensitivity4 = (loss4 - loss) / 0.217391304\n",
    "Sensitivity5 = (loss5 - loss) / 0.244476282\n",
    "Sensitivity6 = (loss6 - loss) / 0.205956096\n",
    "Sensitivity7 = (loss7 - loss) / 0.200793541\n",
    "Sensitivity8 = (loss8 - loss) / 0.228019197\n",
    "Sensitivity9 = (loss9 - loss) / 0.202439338\n",
    "Sensitivity10 = (loss10 - loss) / 0.199596158\n",
    "Sensitivity11 = (loss11 - loss) / 0.252959332\n",
    "Sensitivity12 = (loss12 - loss) / 0.197256351\n",
    "Sensitivity13 = (loss13 - loss) / 0.146958898\n",
    "Sensitivity14 = (loss14 - loss) / 0.146958831\n",
    "Sensitivity15 = (loss15 - loss) / 0.172317183\n",
    "Sensitivity16 = (loss16 - loss) / 0.171775777\n",
    "Sensitivity17 = (loss17 - loss) / 0.179914274\n",
    "Sensitivity18 = (loss18 - loss) / 0.22079327\n",
    "Sensitivity19 = (loss19 - loss) / 0.290946038\n",
    "Sensitivity20 = (loss20 - loss) / 0.200977818\n",
    "Sensitivity21 = (loss21 - loss) / 0.221315114\n",
    "\n",
    "print(Sensitivity1)\n",
    "print(Sensitivity2)\n",
    "print(Sensitivity3)\n",
    "print(Sensitivity4)\n",
    "print(Sensitivity5)\n",
    "print(Sensitivity6)\n",
    "print(Sensitivity7)\n",
    "print(Sensitivity8)\n",
    "print(Sensitivity9)\n",
    "print(Sensitivity10)\n",
    "print(Sensitivity11)\n",
    "print(Sensitivity12)\n",
    "print(Sensitivity13)\n",
    "print(Sensitivity14)\n",
    "print(Sensitivity15)\n",
    "print(Sensitivity16)\n",
    "print(Sensitivity17)\n",
    "print(Sensitivity18)\n",
    "print(Sensitivity19)\n",
    "print(Sensitivity20)\n",
    "print(Sensitivity21)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
