{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/xgf/Disstill_defect_interpretation/Disstill_defect_interpretation2/models/utils.py:18: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from models.utils import brand_new_tfsession, draw_tree\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from models import ConvNet, SoftBinaryDecisionTree\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "sess = brand_new_tfsession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# 检查是否启用了急切执行模式\n",
    "if tf.executing_eagerly():\n",
    "    print(\"Eager execution is enabled.\")\n",
    "else:\n",
    "    print(\"Eager execution is not enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量来控制 TensorFlow 日志级别 \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # 只显示错误信息 \n",
    "# TensorFlow 2.x 中设置日志级别 \n",
    "tf.get_logger().setLevel('ERROR') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 13, 2, 1) (88, 1) (10, 13, 2, 1) (10, 1) (7, 13, 2, 1) (7, 1)\n"
     ]
    }
   ],
   "source": [
    "#上采样\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import *\n",
    "# from keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import xlwt\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "\n",
    "original_data = pd.read_csv('./dataset/AEEEM/EQ.csv')                \n",
    "\n",
    "original_data.isnull().values.any()  # Gives false ie:No null value in dataset\n",
    "original_data = original_data.fillna(value=False)  #将缺失值填充为False\n",
    "original_Y = original_data['class']  # Defective   class   isDefective  defects\n",
    "original_Y = pd.DataFrame(original_Y) \n",
    "original_data = normalization(original_data) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  将数据写入新文件  \n",
    "#original_data.to_excel('C:/Users/lenovo/Desktop/excel/ar6.xls',sheet_name='ar6',index=False)\n",
    "original_X = pd.DataFrame(original_data.drop(['class'], axis=1))  #Defective   class  isDefective  defects\n",
    "#print(original_X)\n",
    "#分为训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(original_X, original_Y, test_size=.1, random_state=12)\n",
    "# now we resample, and from that we take training and validation sets \n",
    "sm = SMOTE(random_state=12, sampling_strategy=1.0) # 解决分类不平衡问题 \n",
    "x, y = sm.fit_resample(x_train, y_train)\n",
    "y_train = pd.DataFrame(y, columns=['class']) #Defective  class  isDefective  defects \n",
    "x_train = pd.DataFrame(x, columns=original_X.columns)\n",
    "#print(x_test) \n",
    "\n",
    "#细分出验证集\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.1, random_state=12)\n",
    "\n",
    "x_train = x_train.values\n",
    "x_val = x_val.values\n",
    "x_test = x_test.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "y_test = y_test.values\n",
    "\n",
    "img_rows, img_cols =  7,3    # 7,3   13,2\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 2 1 2\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols, img_chans, n_classes =  7,3  , 1, 2  #7,3   13,2\n",
    "print(img_rows, img_cols, img_chans, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 2) (10, 2) (7, 2)\n"
     ]
    }
   ],
   "source": [
    "# 将标签转换为独热编码向量\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, n_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将输入数据进行标准化并转换成浮点型\n",
    "x_train = (x_train / np.max(x_train)).astype(np.float32)\n",
    "x_val = (x_val / np.max(x_val)).astype(np.float32)\n",
    "x_test = (x_test / np.max(x_test)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 26), (10, 26), (7, 26))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先将数据展平，变成二维数据\n",
    "x_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
    "x_val_flat = x_val.reshape((x_val.shape[0], -1))\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "x_train_flat.shape, x_val_flat.shape, x_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "n_features = img_rows * img_cols * img_chans\n",
    "tree_depth = 4\n",
    "penalty_strength = 1e+1     \n",
    "penalty_decay = 0.25     \n",
    "ema_win_size = 1000    \n",
    "inv_temp = 0.01  \n",
    "learning_rate = 1e-06  \n",
    "batch_size = 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tree has 16 leaves out of 31 nodes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(None, 2) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = brand_new_tfsession(sess)\n",
    "\n",
    "# 构建g模型\n",
    "g_model_joint = SoftBinaryDecisionTree(tree_depth, n_features, n_classes, \n",
    "    penalty_strength=penalty_strength, penalty_decay=penalty_decay, \n",
    "    inv_temp=inv_temp, ema_win_size=ema_win_size, learning_rate=learning_rate)\n",
    "g_model_joint.build_model()\n",
    "g_model_joint.initialize_variables(sess, x_train_flat, batch_size)\n",
    "\n",
    "# 构建f模型\n",
    "f_model_joint = ConvNet(img_rows, img_cols, img_chans, n_classes)   \n",
    "f_model_joint.build_model()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(f, g, x_test, x_test_flat, y_test):\n",
    "    # 初始化混淆矩阵\n",
    "    conf_matx_fy = np.zeros([2, 2])  # 对于f模型和真实标签y的混淆矩阵\n",
    "    conf_matx_fg = np.zeros([2, 2])  # 对于f模型和g模型的混淆矩阵，用于计算保真度\n",
    "    conf_matx_gy = np.zeros([2, 2])  # 对于g模型和真实标签y的混淆矩阵，用于计算g模型的准确度\n",
    "\n",
    "    # 对整个数据集进行预测\n",
    "    output_f = f.predict(x_test)\n",
    "    output_g = g.predict(x_test_flat)\n",
    "    y = np.argmax(y_test, axis=1)\n",
    "    pred_f = np.argmax(output_f, axis=1)\n",
    "    pred_g = np.argmax(output_g, axis=1)\n",
    "\n",
    "    # 更新混淆矩阵\n",
    "    for i in range(len(y)):\n",
    "        conf_matx_fy[y[i], pred_f[i]] += 1\n",
    "        conf_matx_fg[pred_f[i], pred_g[i]] += 1\n",
    "        conf_matx_gy[y[i], pred_g[i]] += 1\n",
    "\n",
    "    # 计算准确度和保真度\n",
    "    accuracy_f = np.diag(conf_matx_fy).sum() / len(y) \n",
    "    fidelity = np.diag(conf_matx_fg).sum() / len(y)  \n",
    "    accuracy_g = np.diag(conf_matx_gy).sum() / len(y)  \n",
    "\n",
    "    return accuracy_f, fidelity, accuracy_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from joint import train, f_model_evaluate, g_model_evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_model_joint successfully loaded from assets/f_model_joint.hdf5\n",
      "g_model_joint successfully restored from assets/g_model_joint\n",
      "accuracy: 85.71% | loss: 0.6894818544387817\n",
      "accuracy: 71.43% | loss: inf\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import os \n",
    " \n",
    "epochs = 40 \n",
    "batch_size = 64 \n",
    "learning_rate_train = 1e-04\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_train)  \n",
    "# 设置模型保存的路径   \n",
    "f_model_path = 'assets/f_model_joint.hdf5'  \n",
    "g_model_path = 'assets/g_model_joint'   \n",
    "                                       \n",
    "# 检查模型文件是否存在  \n",
    "f_model_exists = os.path.exists(f_model_path)  \n",
    "g_model_exists = os.path.exists(g_model_path + '.index')  \n",
    "\n",
    "# 如果模型文件不存在，则训练模型   \n",
    "if not f_model_exists or not g_model_exists:   \n",
    "    f_model_joint, g_model_joint = train(f_model_joint, g_model_joint, sess, x_train,  \n",
    "                                         x_train_flat, y_train, optimizer, epochs, batch_size=batch_size)  \n",
    "    # 保存 f_model_jonit \n",
    "    f_model_joint.model.save(f_model_path)   \n",
    "    print(\"Model saved to %s\" % f_model_path)   \n",
    "\n",
    "    # 保存 g_model_joint    \n",
    "    g_model_joint.saver.save(sess, g_model_path)  \n",
    "    print(\"Model saved to %s\" % g_model_path)  \n",
    "else:\n",
    "    # 加载 f_model_jonit \n",
    "    f_model_joint.model = load_model(f_model_path)  \n",
    "    print(\"f_model_joint successfully loaded from %s\" % f_model_path)  \n",
    "\n",
    "    # 加载 g_model_joint \n",
    "    g_model_joint.saver.restore(sess, g_model_path) \n",
    "    print(\"g_model_joint successfully restored from %s\" % g_model_path) \n",
    "\n",
    "# 进行模型性能评估  \n",
    "f_model_joint.evaluate(x_test, y_test) \n",
    "g_model_joint.evaluate(x=x_test_flat, y=y_test, batch_size=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_model_joint:\n",
      "accuracy: 85.71% | loss: 0.6894818544387817\n",
      "g_model_joint:\n",
      "accuracy: 71.43% | loss: 36.634307861328125\n"
     ]
    }
   ],
   "source": [
    "# 进行模型评估\n",
    "print(\"f_model_joint:\")\n",
    "f_model_joint.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"g_model_joint:\")\n",
    "g_model_joint.evaluate(x=x_test_flat, y=y_test, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of f (in %): 85.71\n",
      "Accuracy of g (in %): 71.43\n",
      "Fidelity (in %): 85.71\n"
     ]
    }
   ],
   "source": [
    "# 计算保真度\n",
    "f_joint_acc, fidelity, g_joint_acc = analyze(f_model_joint, g_model_joint, x_test, x_test_flat, y_test)\n",
    "\n",
    "print(\"Accuracy of f (in %): {:.2f}\".format(f_joint_acc * 100))\n",
    "print(\"Accuracy of g (in %): {:.2f}\".format(g_joint_acc * 100))\n",
    "print(\"Fidelity (in %): {:.2f}\".format(fidelity * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
